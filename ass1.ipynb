{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Assignment 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import heapq\n",
    "import copy\n",
    "from itertools import count\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0 # this can be altered to provide different accuracy, see Dataset.split() (try 18 for best results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Constants for the different conformity measures, to be used when instantiating a new Conformal object.\n",
    "   See Conformal class.\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "DIFFERENT_CLASS = 1\n",
    "ONE_OVER_SAME_CLASS = 2\n",
    "DIFFERENT_OVER_SAME_CLASS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Class that represents the Dataset that will be used for predictions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, name, samples, labels):\n",
    "        \"\"\"Takes a name for the dataset, an array of samples and an array of their corresponding labels. \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.name = name\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.dataset = self.fit(samples, labels)\n",
    "        self.label_set = self.extract_labels()   \n",
    "        self.test_set, self.training_set, self.actual_test_labels = self.split()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        data = \"\"\n",
    "        for sample in self.dataset:\n",
    "           data += str(sample) + \"\\n\"\n",
    "        return data\n",
    "        \n",
    "    def extract_labels(self):\n",
    "        \"\"\"Return a set of all unique labels for this dataset.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        labels = set()\n",
    "\n",
    "        for i in range(len(self.dataset)):\n",
    "            if not self.dataset[i][-1] in labels:\n",
    "                labels.add(self.dataset[i][-1])\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_actual_test_labels(self):\n",
    "        return self.actual_test_labels\n",
    "        \n",
    "    def get_label_set(self):\n",
    "        return self.label_set\n",
    "    \n",
    "    def get_test_set(self):\n",
    "        return self.test_set\n",
    "    \n",
    "    def get_training_set(self):\n",
    "        return self.training_set\n",
    "    \n",
    "    def fit(self, samples, labels):\n",
    "        \"\"\"Takes an array of samples and an array of their correspondiong labels.\n",
    "           Returns a new array where each element is the concatenation of a sample and its corresponding label.\n",
    "           \n",
    "        \"\"\"\n",
    "\n",
    "        features = samples.shape[1] + 1\n",
    "        labelled_samples = np.zeros((len(samples), features))\n",
    "\n",
    "        for i in range(len(labelled_samples)):\n",
    "            sample = samples[i]\n",
    "            label = [labels[i]]\n",
    "            labelled_samples[i] = np.concatenate([sample,label])\n",
    "\n",
    "        return labelled_samples\n",
    "    \n",
    "    def split(self):\n",
    "        \"\"\"Split the dataset into a test set and a training set.\n",
    "            Return an array for the test set, an array for the training set and an array for the test set labels.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        training_samples, test_samples, training_labels, test_labels = train_test_split(self.samples, self.labels, random_state=RANDOM_STATE)\n",
    "        test_set = self.fit(test_samples, test_labels)\n",
    "        training_set = self.fit(training_samples, training_labels)\n",
    "        return test_set, training_set, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NearestNeighbours Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Class that represents the Nearest Neighbours model.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class NearestNeighbours:\n",
    "    \n",
    "    def __init__(self, dataset, neighbours=1):\n",
    "        \"\"\"Takes a Dataset object and an optional parameter for number of neighbours, which is 1 by default. \n",
    "        \n",
    "        \"\"\"        \n",
    "        \n",
    "        # Make sure user can't choose less than 1 nearest neighbour\n",
    "        if neighbours < 1:\n",
    "            self.kNeighbours = 1\n",
    "        else:\n",
    "            self.kNeighbours = neighbours\n",
    "            \n",
    "        self.dataset = dataset\n",
    "        self.test_set = self.get_test_set()\n",
    "        self.training_set = self.get_training_set()\n",
    "        self.predictions = None\n",
    "        self.tiebreaker = count()\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        return self.dataset\n",
    "    \n",
    "    def get_dataset_name(self):\n",
    "        return self.dataset.get_name()\n",
    "    \n",
    "    def get_test_set(self):\n",
    "        return self.dataset.get_test_set()\n",
    "    \n",
    "    def get_training_set(self):\n",
    "        return self.dataset.get_training_set()\n",
    "        \n",
    "    def get_neighbours(self):\n",
    "        return self.kNeighbours\n",
    "    \n",
    "    def find_knn(self):\n",
    "        nearest_neighbours = np.zeros((len(self.training_set), self.kNeighbours))\n",
    "        print(str(nearest_neighbours))\n",
    "    \n",
    "    def actual_labels(self):\n",
    "        return self.dataset.get_actual_test_labels()\n",
    "    \n",
    "    def euclidean(self, x, y):\n",
    "        \"\"\"Takes two vectors as parameters and returns the Euclidean distance between those two points.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        ed = 0\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            ed += (x[i] - y[i])**2\n",
    "\n",
    "        return np.sqrt(ed)\n",
    "    \n",
    "    def find_nearest_neighbour(self, test_sample, training_set):\n",
    "        \"\"\"Takes a test sample and a training set and finds the K nearest neighbours to the test sample in the training set.\n",
    "           The K nearest neighbours are analysed for their labels and the majority label is the one that will be predicted for the test sample.\n",
    "           In case of ties, the first label is chosen.\n",
    "           Returns the nearest labelled sample and the distance of this sample to the test sample.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Make sure that K is not larger than the training set\n",
    "        if self.kNeighbours > len(training_set):\n",
    "            k = len(training_set)\n",
    "        else:\n",
    "            k = self.kNeighbours\n",
    "            \n",
    "        neighbours = []\n",
    "        heapq.heapify(neighbours)\n",
    "        nearest_neighbours = np.zeros((k, 3), dtype=object)\n",
    "        nearest_labels = []    \n",
    "\n",
    "        for i in range(len(training_set)):\n",
    "            ed = self.euclidean(test_sample, training_set[i][:-1])\n",
    "            entry = [ed]\n",
    "            entry.append(next(self.tiebreaker)) \n",
    "            entry.append(training_set[i])\n",
    "            heapq.heappush(neighbours, entry)        \n",
    "            \n",
    "        for i in range(k):\n",
    "            entry = heapq.heappop(neighbours)\n",
    "            nearest_neighbours[i] = entry\n",
    "            nearest_labels.append(nearest_neighbours[i][2][-1])\n",
    "        \n",
    "        (values, counts) = np.unique(nearest_labels, return_counts=True)\n",
    "        index = np.argmax(counts)\n",
    "        \n",
    "        closest_labelled_sample = nearest_neighbours[index][2]\n",
    "        closest_distance = nearest_neighbours[index][0]\n",
    "        \n",
    "        return closest_labelled_sample, closest_distance    \n",
    "    \n",
    "    def predict_labels(self):\n",
    "        \"\"\"Predicts the label for each sample in the test set using the nearest neighbour algorithm.\n",
    "           Stores an array of all the predicted labels in the instance variable self.predictions.\n",
    "           \n",
    "        \"\"\"\n",
    "        \n",
    "        self.predictions = np.zeros((len(self.test_set)))\n",
    "\n",
    "        for i in range(len(self.test_set)):\n",
    "            test_sample = self.test_set[i][:-1]\n",
    "            closest_labelled_sample = self.find_nearest_neighbour(test_sample, self.training_set)\n",
    "            closest_label = closest_labelled_sample[0][-1:]\n",
    "            self.predictions[i] = closest_label\n",
    "\n",
    "    def score(self):\n",
    "        \"\"\"Compares the predicted labels with the actual labels and prints the accuracy rate and error rate of the model.\n",
    "           \n",
    "        \"\"\"\n",
    "        \n",
    "        dataset_name = self.get_dataset_name()\n",
    "        score = 1 - np.mean(self.predictions == self.actual_labels())\n",
    "        errors = np.size(self.predictions) - np.count_nonzero(self.predictions == self.actual_labels())\n",
    "        print(\"Number of errors in \" + dataset_name + \" predictions is: \" + str(errors) + \" out of \" + str(len(self.predictions)))\n",
    "        print(\"The error rate for the \" + dataset_name + \" predictions is: \" + str(score) + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformal Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Class that represents the Conformal prediction model.\n",
    "   This is a subclass of the NearestNeighbours class.\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "class Conformal(NearestNeighbours):\n",
    "    \n",
    "    def __init__(self, dataset, conformity_measure=DIFFERENT_OVER_SAME_CLASS):\n",
    "        \"\"\"Takes a Dataset object and an optional parameter for the conformity measure, \n",
    "           which is DIFFERENT_OVER_SAME_CLASS by default. See Constants at top for more options.\n",
    "        \n",
    "        \"\"\"  \n",
    "        \n",
    "        super().__init__(dataset, neighbours=1)\n",
    "        self.conformity_measure = conformity_measure\n",
    "        self.tiebreaker = count()\n",
    "        self.training_set_scores = self.nn_training_set()\n",
    "\n",
    "    def label_set(self):\n",
    "        \"\"\"Return the set of possible labels in this dataset.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        return self.dataset.get_label_set()\n",
    "    \n",
    "    def separate_classes(self, test_sample):\n",
    "        \"\"\"Takes a test sample and returns two arrays, same_class and different_class.\n",
    "           same_class contains all labelled samples from training set with the same label as test_sample.\n",
    "           different_class contains all labelled samples from training set with a different label from test_sample.\n",
    "           \n",
    "        \"\"\"\n",
    "        same_class = []\n",
    "        different_class = []\n",
    "\n",
    "        for i in range(len(self.training_set)):\n",
    "            if self.training_set[i][-1] == test_sample[-1]:\n",
    "                same_class.append(self.training_set[i])\n",
    "            else:\n",
    "                different_class.append(self.training_set[i])\n",
    "        \n",
    "        # Make sure the test sample isn't kept in the same_class array.        \n",
    "        for i in range(len(same_class)):\n",
    "            if np.array_equal(same_class[i], test_sample):\n",
    "                same_class = np.delete(same_class, i, 0)\n",
    "                break\n",
    "\n",
    "        same_class = np.array(same_class)   \n",
    "        different_class = np.array(different_class)\n",
    "\n",
    "        return same_class, different_class\n",
    "    \n",
    "    def conf_score(self, nearest_diff_distance, nearest_same_distance):\n",
    "        \"\"\"Takes two distances and calculates the conformity score based on the current\n",
    "           conformity measure being used.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.conformity_measure == DIFFERENT_CLASS:\n",
    "            conformity_score = nearest_diff_distance\n",
    "        elif self.conformity_measure == ONE_OVER_SAME_CLASS and nearest_same_distance != 0:\n",
    "            conformity_score = 1 / nearest_same_distance                  \n",
    "        elif nearest_diff_distance == 0 and nearest_same_distance == 0:\n",
    "            conformity_score = 0              \n",
    "        elif nearest_same_distance == 0:\n",
    "            conformity_score = math.inf    \n",
    "        else:\n",
    "            conformity_score = nearest_diff_distance / nearest_same_distance                       \n",
    "            \n",
    "        return conformity_score    \n",
    "    \n",
    "    def nn_training_set(self):\n",
    "        \"\"\"Compares each training sample with the rest of the training set and calculates its conformity score.\n",
    "           Return an array of labelled training samples along with their conformity scores.\n",
    "           Make the array length 1 more than training set length and leave last index blank which will be \n",
    "           used to temporarily store a test sample when it is being measured against the training set - \n",
    "           see self.nn_test_sample.\n",
    "           \n",
    "        \"\"\"\n",
    "\n",
    "        scores = np.zeros(len(self.training_set) + 1, dtype=object)\n",
    "\n",
    "        for i in range(len(self.training_set)):\n",
    "            labelled_sample = self.training_set[i]\n",
    "            same_class, different_class = self.separate_classes(labelled_sample)         \n",
    "\n",
    "            nn_different_class, nn_different_distance = self.find_nearest_neighbour(labelled_sample[:-1], different_class)\n",
    "            nn_same_class, nn_same_distance = self.find_nearest_neighbour(labelled_sample[:-1], same_class)                    \n",
    "\n",
    "            conformity_score = self.conf_score(nn_different_distance, nn_same_distance)\n",
    "\n",
    "            entry = [conformity_score]\n",
    "            entry.append(next(self.tiebreaker)) \n",
    "            entry.append(labelled_sample)\n",
    "            entry.append(nn_different_distance)\n",
    "            entry.append(nn_same_distance)\n",
    "            scores[i] = entry\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def nn_test_sample(self, sample):\n",
    "        \"\"\"Takes a test sample and finds the nearest distance between this and a sample in the training set with\n",
    "           the same label, as well as the nearest distance to a sample in the training set with a different label.\n",
    "           Makes a copy of the training set scores array created in self.nn_training_set. In each iteration check if\n",
    "           the euclidean distance calculated is less than the distance already stored for that particular training sample,\n",
    "           if so this will only be updated in the copied array.\n",
    "           Return an array with the training set and this specific test sample along with the conformity scores for each sample.\n",
    "           \n",
    "        \"\"\"\n",
    "        \n",
    "        test_sample = sample[:-1]\n",
    "        test_label = sample[-1]\n",
    "        nearest_same_distance = math.inf\n",
    "        nearest_diff_distance = math.inf\n",
    "        train_set_scores = copy.deepcopy(self.training_set_scores)\n",
    "        changed = False\n",
    "        \n",
    "        for i in range(len(train_set_scores) - 1):\n",
    "            training_sample = train_set_scores[i][2][:-1]\n",
    "            training_label = train_set_scores[i][2][-1]            \n",
    "            ed = self.euclidean(test_sample, training_sample)\n",
    "            \n",
    "            if (test_label == training_label):\n",
    "                if ed <= nearest_same_distance:\n",
    "                    nearest_same_distance = ed            \n",
    "                if ed <= train_set_scores[i][4]:\n",
    "                    train_set_scores[i][4] = ed\n",
    "                    changed = True\n",
    "            else:\n",
    "                if ed <= nearest_diff_distance:\n",
    "                    nearest_diff_distance = ed\n",
    "                if ed <= train_set_scores[i][3]:\n",
    "                    train_set_scores[i][3] = ed\n",
    "                    changed = True\n",
    "            \n",
    "            '''\n",
    "               Checks if either of the distances for this training sample have been changed, if so, the conformity\n",
    "               score will be recalculated\n",
    "            '''\n",
    "            if changed:\n",
    "                train_set_scores[i][0] = self.conf_score(train_set_scores[i][3], train_set_scores[i][4])\n",
    "                changed = False\n",
    "            \n",
    "        conformity_score = self.conf_score(nearest_diff_distance, nearest_same_distance)\n",
    "\n",
    "        entry = [conformity_score]\n",
    "        entry.append(next(self.tiebreaker))\n",
    "        entry.append(sample)\n",
    "        entry.append(nearest_diff_distance)\n",
    "        entry.append(nearest_same_distance)\n",
    "        test = np.array([entry], object)\n",
    "        train_set_scores[-1] = entry\n",
    "\n",
    "        return train_set_scores  \n",
    "    \n",
    "    def pval(self, test_sample, scores_list):\n",
    "        \"\"\"Takes a test sample and the training set conformity scores created in self.nn_test_sample, and calculates \n",
    "           the P Value for this test sample.\n",
    "           Converts the array of scores into a heap. The heap stores each labelled training sample with the conformity \n",
    "           score used as the means of prioritising the data. Pop will always remove the smallest conformity score first. \n",
    "           Pop each entry until test sample is found.\n",
    "           Return the P Value for this specific test sample.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        rank = 0\n",
    "        scores = copy.deepcopy(scores_list)\n",
    "        scores = scores.tolist()\n",
    "        num_of_samples = len(scores)\n",
    "        heapq.heapify(scores)\n",
    "\n",
    "        for i in range(len(scores_list)):\n",
    "            sample = heapq.heappop(scores)\n",
    "\n",
    "            if np.array_equal(sample[2], test_sample):\n",
    "                rank = i + 1\n",
    "                break\n",
    "\n",
    "        p_value = rank / num_of_samples\n",
    "        \n",
    "        return p_value   \n",
    "    \n",
    "    def false_pvalues(self):\n",
    "        \"\"\"Calculates the average false P Values for each test sample.\n",
    "           Iterate through each sample in the test set and for each possible label calculates the P Value. This is\n",
    "           used to calculate the false P Value and then the average false P Value.\n",
    "           Return an array with the average false P Value for each test sample.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        p_val = -math.inf\n",
    "        count = 0    \n",
    "        false_pval_list = np.zeros((len(self.test_set), 1))\n",
    "        \n",
    "        for test_sample in self.test_set:\n",
    "            p_val = -math.inf\n",
    "            false_pval = 0\n",
    "            real_label = test_sample[-1]\n",
    "\n",
    "            for label in self.label_set():\n",
    "                sample = np.concatenate((test_sample[:-1], [label]))\n",
    "                scores = self.nn_test_sample(sample)\n",
    "                current_pv = self.pval(sample, scores)\n",
    "\n",
    "                if current_pv >= p_val:\n",
    "                    p_val = current_pv\n",
    "                if label != real_label:\n",
    "                    false_pval += current_pv\n",
    "\n",
    "            avg_false_pval = false_pval / (len(self.label_set()) - 1)\n",
    "            false_pval_list[count] = avg_false_pval\n",
    "            count += 1                \n",
    "\n",
    "        return false_pval_list  \n",
    "    \n",
    "    def avg_false_pval(self):\n",
    "        \"\"\"Calculates the average false P Values for each test sample and then returns the average of all these values.\n",
    "           Returns an integer for the average false P Value.\n",
    "           \n",
    "        \"\"\"\n",
    "        \n",
    "        false_pvals = self.false_pvalues()\n",
    "        \n",
    "        total_false_pvals = 0\n",
    "        \n",
    "        for pval in false_pvals:\n",
    "            total_false_pvals += pval[0]\n",
    "            \n",
    "        avg_false_pval = total_false_pvals / len(false_pvals)\n",
    "        \n",
    "        return avg_false_pval\n",
    "    \n",
    "    def score(self):\n",
    "        \"\"\"Evaluates the accuracy of the Conformal Prediction model and prints out a message with the average false P Value.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        dataset_name = self.get_dataset_name()\n",
    "        score = self.avg_false_pval()\n",
    "\n",
    "        print(\"Average False P Value in \" + dataset_name + \" conformal predictions is: \" + str(score))\n",
    "        print(\"(This took \" + str(time.time() - start) + \" seconds to calculate.)\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and split the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris() # load iris data\n",
    "\n",
    "X_ion = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\", usecols=np.arange(34)) # extract samples from ionosphere\n",
    "y_ion = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\", usecols=34, dtype='int') # extract labels from ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = Dataset(\"Iris\", iris.data, iris.target)\n",
    "ion_dataset = Dataset(\"Ionosphere\", X_ion, y_ion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEAREST NEIGHBOUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the NearestNeighbours models for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_knn = NearestNeighbours(iris_dataset)\n",
    "ion_knn = NearestNeighbours(ion_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the labels for each test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_knn.predict_labels()\n",
    "ion_knn.predict_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the accuracy and error rates of predictions on Nearest Neighbour model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Iris predictions is: 1 out of 38\n",
      "The error rate for the Iris predictions is: 0.02631578947368418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_knn.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Ionosphere predictions is: 13 out of 88\n",
      "The error rate for the Ionosphere predictions is: 0.1477272727272727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ion_knn.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the value of K to see what difference this will make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Iris predictions is: 1 out of 38\n",
      "The error rate for the Iris predictions is: 0.02631578947368418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_knn = NearestNeighbours(iris_dataset, 3)\n",
    "iris_knn.predict_labels()\n",
    "iris_knn.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Ionosphere predictions is: 12 out of 88\n",
      "The error rate for the Ionosphere predictions is: 0.13636363636363635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ion_knn = NearestNeighbours(ion_dataset, 3)\n",
    "ion_knn.predict_labels()\n",
    "ion_knn.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Iris predictions is: 1 out of 38\n",
      "The error rate for the Iris predictions is: 0.02631578947368418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_knn = NearestNeighbours(iris_dataset, 5)\n",
    "iris_knn.predict_labels()\n",
    "iris_knn.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Ionosphere predictions is: 13 out of 88\n",
      "The error rate for the Ionosphere predictions is: 0.1477272727272727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ion_knn = NearestNeighbours(ion_dataset, 5)\n",
    "ion_knn.predict_labels()\n",
    "ion_knn.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Iris predictions is: 1 out of 38\n",
      "The error rate for the Iris predictions is: 0.02631578947368418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_knn = NearestNeighbours(iris_dataset, 9)\n",
    "iris_knn.predict_labels()\n",
    "iris_knn.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Ionosphere predictions is: 14 out of 88\n",
      "The error rate for the Ionosphere predictions is: 0.15909090909090906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ion_knn = NearestNeighbours(ion_dataset, 9)\n",
    "ion_knn.predict_labels()\n",
    "ion_knn.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30 Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Iris predictions is: 1 out of 38\n",
      "The error rate for the Iris predictions is: 0.02631578947368418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_knn = NearestNeighbours(iris_dataset, 30)\n",
    "iris_knn.predict_labels()\n",
    "iris_knn.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Ionosphere predictions is: 12 out of 88\n",
      "The error rate for the Ionosphere predictions is: 0.13636363636363635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ion_knn = NearestNeighbours(ion_dataset, 30)\n",
    "ion_knn.predict_labels()\n",
    "ion_knn.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Iris predictions is: 2 out of 38\n",
      "The error rate for the Iris predictions is: 0.052631578947368474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_knn = NearestNeighbours(iris_dataset, 100)\n",
    "iris_knn.predict_labels()\n",
    "iris_knn.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors in Ionosphere predictions is: 9 out of 88\n",
      "The error rate for the Ionosphere predictions is: 0.10227272727272729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ion_knn = NearestNeighbours(ion_dataset, 100)\n",
    "ion_knn.predict_labels()\n",
    "ion_knn.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion on KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By playing with the value of K we can see that the accuracy of the model varies. In some cases there were no differences, particularly with the Iris dataset. This could be because it is relatively small and so there is less chance of finding anamolous data to skew our results.\n",
    "\n",
    "But looking at the Ionosphere dataset we can see that our predictions are less accurate when using 9 neighbours, more accurate when using 30 neighbours and even more accurate when using 100 neighbours. Having said that, using 100 neighbours for the Iris dataset returns a worse score.\n",
    "\n",
    "The accuracy is also dependent on the random state we choose in the train_test_split method. Please alter the value of the RANDOM_STATE constant at the top and restart and run all cells. A random state of 18 provides a more favourable score and returns no errors for the Iris predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFORMAL PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Conformal objects for both datasets and for each conformity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_conformal1 = Conformal(iris_dataset, conformity_measure=DIFFERENT_CLASS)\n",
    "iris_conformal2 = Conformal(iris_dataset, conformity_measure=ONE_OVER_SAME_CLASS)\n",
    "iris_conformal3 = Conformal(iris_dataset, conformity_measure=DIFFERENT_OVER_SAME_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ion_conformal1 = Conformal(ion_dataset, conformity_measure=DIFFERENT_CLASS)\n",
    "ion_conformal2 = Conformal(ion_dataset, conformity_measure=ONE_OVER_SAME_CLASS)\n",
    "ion_conformal3 = Conformal(ion_dataset, conformity_measure=DIFFERENT_OVER_SAME_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the conformal predictions for each dataset and for each conformity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average False P Value in Iris conformal predictions is: 0.04448067070330696\n",
      "(This took 0.2781543731689453 seconds to calculate.)\n",
      "\n",
      "\n",
      "Average False P Value in Iris conformal predictions is: 0.02619934792734048\n",
      "(This took 0.2974226474761963 seconds to calculate.)\n",
      "\n",
      "\n",
      "Average False P Value in Iris conformal predictions is: 0.011294829995342344\n",
      "(This took 0.30892515182495117 seconds to calculate.)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_conformal1.score() # DIFFERENT_CLASS\n",
    "iris_conformal2.score() # ONE_OVER_SAME_CLASS\n",
    "iris_conformal3.score() # DIFFERENT_OVER_SAME_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average False P Value in Ionosphere conformal predictions is: 0.36664944903581276\n",
      "(This took 1.4453871250152588 seconds to calculate.)\n",
      "\n",
      "\n",
      "Average False P Value in Ionosphere conformal predictions is: 0.21651170798898073\n",
      "(This took 1.5119688510894775 seconds to calculate.)\n",
      "\n",
      "\n",
      "Average False P Value in Ionosphere conformal predictions is: 0.06099345730027552\n",
      "(This took 1.5075788497924805 seconds to calculate.)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ion_conformal1.score() # DIFFERENT_CLASS\n",
    "ion_conformal2.score() # ONE_OVER_SAME_CLASS\n",
    "ion_conformal3.score() # DIFFERENT_OVER_SAME_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion on Conformal Prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both datasets we can see that using the default conformity measure (i.e. the distance to the nearest sample of a different class over the distance to the nearest sample of the same class) produces a better result than the other conformity measures.\n",
    "\n",
    "The accuracy is also dependent on the random state we choose in the train_test_split method. Please alter the value of the RANDOM_STATE constant at the top and restart and run all cells. A random state of 18 provides a more favourable score.\n",
    "\n",
    "I suppose there is an element of luck in regards to the test and training sets that the random state generates and it just so happens that using a state of 18 provides a more favourable test/training set for making accurate predictions than a state of 0 generates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
